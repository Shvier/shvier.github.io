<!doctype html><html class="not-ready lg:text-base" style=--bg:#faf8f1 lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Polynomial Interpolation and FFT - Barry's Site</title>
<meta name=theme-color><meta name=description content="A polynomial can be represented in two forms: the coefficients, and the evaluations (or point-value). Polynomial interpolation is to construct polynomial from the point values. There are three well-known ways to interpolate a polynomial: the Lagrange interpolation, the Newton interpolation, and the Vandermonde matrix. The biggest difference between Lagrange and Newton is Newton&rsquo;s is faster for incremental interpolation while Lagrange&rsquo;s is more efficient for the same set of points. However, the approaches of Lagrange and Newton take $O(n^2)$ time and Vandermonde takes $O(n^3)$, but the time complexity can be boosted to $O(n\log{n})$ with the help of the fast Fourier transform (FFT), strictly, the inverse FFT (IFFT)."><meta name=author content="Barry's Site"><link rel="preload stylesheet" as=style href=https://shvier.github.io/main.min.css><link rel=preload as=image href=https://shvier.github.io/theme.png><link rel=preload as=image href=https://shvier.github.io/twitter.svg><link rel=preload as=image href=https://shvier.github.io/github.svg><script defer src=https://shvier.github.io/highlight.min.js onload=hljs.initHighlightingOnLoad()></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css integrity=sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js integrity=sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",()=>renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1}))</script><link rel=icon href=https://shvier.github.io/favicon.ico><link rel=apple-touch-icon href=https://shvier.github.io/apple-touch-icon.png><meta name=generator content="Hugo 0.126.1"><meta itemprop=name content="Polynomial Interpolation and FFT"><meta itemprop=description content="A polynomial can be represented in two forms: the coefficients, and the evaluations (or point-value). Polynomial interpolation is to construct polynomial from the point values. There are three well-known ways to interpolate a polynomial: the Lagrange interpolation, the Newton interpolation, and the Vandermonde matrix. The biggest difference between Lagrange and Newton is Newton’s is faster for incremental interpolation while Lagrange’s is more efficient for the same set of points. However, the approaches of Lagrange and Newton take $O(n^2)$ time and Vandermonde takes $O(n^3)$, but the time complexity can be boosted to $O(n\log{n})$ with the help of the fast Fourier transform (FFT), strictly, the inverse FFT (IFFT)."><meta itemprop=datePublished content="2024-08-20T14:47:41-04:00"><meta itemprop=dateModified content="2024-08-22T20:16:56+00:00"><meta itemprop=wordCount content="1250"><meta property="og:url" content="https://shvier.github.io/posts/2024/0820/polynomial-interpolation-and-fft/"><meta property="og:site_name" content="Barry's Site"><meta property="og:title" content="Polynomial Interpolation and FFT"><meta property="og:description" content="A polynomial can be represented in two forms: the coefficients, and the evaluations (or point-value). Polynomial interpolation is to construct polynomial from the point values. There are three well-known ways to interpolate a polynomial: the Lagrange interpolation, the Newton interpolation, and the Vandermonde matrix. The biggest difference between Lagrange and Newton is Newton’s is faster for incremental interpolation while Lagrange’s is more efficient for the same set of points. However, the approaches of Lagrange and Newton take $O(n^2)$ time and Vandermonde takes $O(n^3)$, but the time complexity can be boosted to $O(n\log{n})$ with the help of the fast Fourier transform (FFT), strictly, the inverse FFT (IFFT)."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-20T14:47:41-04:00"><meta property="article:modified_time" content="2024-08-22T20:16:56+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Polynomial Interpolation and FFT"><meta name=twitter:description content="A polynomial can be represented in two forms: the coefficients, and the evaluations (or point-value). Polynomial interpolation is to construct polynomial from the point values. There are three well-known ways to interpolate a polynomial: the Lagrange interpolation, the Newton interpolation, and the Vandermonde matrix. The biggest difference between Lagrange and Newton is Newton’s is faster for incremental interpolation while Lagrange’s is more efficient for the same set of points. However, the approaches of Lagrange and Newton take $O(n^2)$ time and Vandermonde takes $O(n^3)$, but the time complexity can be boosted to $O(n\log{n})$ with the help of the fast Fourier transform (FFT), strictly, the inverse FFT (IFFT)."><link rel=canonical href=https://shvier.github.io/posts/2024/0820/polynomial-interpolation-and-fft/></head><body class="text-black duration-200 ease-out dark:text-white"><header class="mx-auto flex h-[4.5rem] max-w-[--w] px-8 lg:justify-center"><div class="relative z-50 mr-auto flex items-center"><a class="-translate-y-[1px] text-2xl font-medium" href=https://shvier.github.io/>Barry's Site</a><div class="btn-dark text-[0] ml-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]" role=button aria-label=Dark></div></div><div class="btn-menu relative z-50 -mr-8 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden" role=button aria-label=Menu></div><script>const htmlClass=document.documentElement.classList;setTimeout(()=>{htmlClass.remove("not-ready")},10);const btnMenu=document.querySelector(".btn-menu");btnMenu.addEventListener("click",()=>{htmlClass.toggle("open")});const metaTheme=document.querySelector('meta[name="theme-color"]'),lightBg="#faf8f1".replace(/"/g,""),setDark=e=>{metaTheme.setAttribute("content",e?"#000":lightBg),htmlClass[e?"add":"remove"]("dark"),localStorage.setItem("dark",e)},darkScheme=window.matchMedia("(prefers-color-scheme: dark)");if(htmlClass.contains("dark"))setDark(!0);else{const e=localStorage.getItem("dark");setDark(e?e==="true":darkScheme.matches)}darkScheme.addEventListener("change",e=>{setDark(e.matches)});const btnDark=document.querySelector(".btn-dark");btnDark.addEventListener("click",()=>{setDark(localStorage.getItem("dark")!=="true")})</script><div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"><nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-10"><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal" href=/about/>About</a></nav><nav class="mt-12 flex justify-center space-x-10 dark:invert lg:ml-14 lg:mt-0 lg:items-center"><a class="h-7 w-7 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./twitter.svg) href=https://twitter.com/barryllvm target=_blank rel=me>twitter
</a><a class="h-7 w-7 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./github.svg) href=https://github.com/Shvier target=_blank rel=me>github</a></nav></div></header><main class="prose prose-neutral relative mx-auto min-h-[calc(100%-9rem)] max-w-[--w] px-8 pb-16 pt-14 dark:prose-invert"><article><header class=mb-20><h1 class="!my-0 pb-2.5">Polynomial Interpolation and FFT</h1><div class="text-sm opacity-50" style=display:flex;align-items:center><time>Created on Aug 20, 2024</time>
<time>&nbsp•&nbspModified on Aug 22, 2024</time></div></header><section><p>A polynomial can be represented in two forms: the coefficients, and the evaluations (or point-value). Polynomial interpolation is to construct polynomial from the point values. There are three well-known ways to interpolate a polynomial: the Lagrange interpolation, the Newton interpolation, and the Vandermonde matrix. The biggest difference between Lagrange and Newton is Newton&rsquo;s is faster for incremental interpolation while Lagrange&rsquo;s is more efficient for the same set of points. However, the approaches of Lagrange and Newton take $O(n^2)$ time and Vandermonde takes $O(n^3)$, but the time complexity can be boosted to $O(n\log{n})$ with the help of the fast Fourier transform (FFT), strictly, the inverse FFT (IFFT).</p><p>The basic idea of FFT exploits divide and conquer. That is, a polynomial can be decomposed into two parts with half the degree, one part records the coefficients in odd degrees while the other is for the coefficients in even degrees. Suppose $d$ is the power of two; given a polynomial $f\in\mathbb{F}_{\lt{d}}[X]$ and let $a_i$ denote the coefficient of $f$, we have</p>$$
\begin{align}
f&=a_0+a_1x+a_2x^2+\cdots+a_{d-1}x^{d-1} \\
&=a_0+a_2x^2+\cdots+a_{d-2}x^{d-2}+x\cdot(a_1+a_3x^2+\cdots+a_{d-1}x^{d-2}) \\
&=f_E(x)+x\cdot{f_O(x)}
\end{align}
$$<p>It is clear that $f_E$ and $f_O$ have half of the degree $d$ and half of the possible values of $x$ (call it domain). And if we know the evaluations of $f_E(x),f_O(x)$, we can compute $f(x),f(-x)$ with one addition and one multiplication. That means we successfully halve the computation of evaluating $f$ for all possible $x$. By recursively performing the same process, we can get one one-degree polynomial and one constant polynomial in $\log{d}$ steps, so the computation is reduced to logarithm time. To demonstrate the algorithm with a concrete example, I will use the data from <a href=https://web.archive.org/web/20231102070604/https://vitalik.ca/general/2019/05/12/fft.html>Vitalik&rsquo;s post about FFT</a>. Given the polynomial $f(x)=3+x+4x^2+x^3+5x^4+9x^5+2x^6+6x^7$ and the domain $[1,85,148,111,336,252,189,226]$, we have</p>$$
\begin{align}
f(x)&=3+x+4x^2+x^3+5x^4+9x^5+2x^6+6x^7 \\
&=3+4x^2+5x^4+2x^6+x\cdot(1+x^2+9x^4+6x^6) \\
&=3+4\chi+5\chi^2+2\chi^3+x\cdot(1+\chi+9\chi^2+6\chi^3) \\
&=3+5\chi^2+\chi(4+2\chi^2)+x\cdot(1+9\chi^2+\chi\cdot(1+6\chi^2)) \\
&=3+5\varkappa+\chi(4+2\varkappa)+x\cdot(1+9\varkappa+\chi\cdot(1+6\varkappa))
\end{align}
$$<p>where $\chi=x^2,\varkappa=\chi^2=x^4$. We can observe that $f$ is decomposed into several one-degree and constant polynomials in 3 steps, which means we can evaluate the polynomial for all the points on the domain in logarithm time. You might have questions about how it relates to polynomial interpolation. The answer is if there exists an algorithm allowing us to convert the coefficients into the evaluations efficiently, then the interpolation can also be done quickly by inversing the algorithm.</p><p>We can see the algorithm requires the degree of the polynomial to be the power of two. This seems no problem because we can zero the coefficients for the polynomial less than the degree or sparse. The challenge is the evaluation points must have some special values to satisfy the recursion, i.e., the value of squaring $x$ multiple times should be on the same domain. This means FFT works on a finite field under multiplication and the order of the generator is the power of two, which is exactly the property of the roots of unity. In the above example, $85$ is the root of unity with order $8$, and we can verify that $85$ modulo $337$ satisfies the requirement. We say $85$ is an eighth root of unity modulo $337$.</p><p>Based on the above knowledge, now we can convert a polynomial between the coefficients and the point values in logarithm time. Let us see the FFT first and the IFFT later using a concrete example. To evaluate $f(x)=3+x+4x^2+x^3+5x^4+9x^5+2x^6+6x^7$ over the domain $[1,85,148,111,336,252,189,226]$, we apply the algorithm as follows:</p><ol><li>Decompose $f(x)$ into $f_E^{[1]}(x),f_O^{[1]}(x)$ such that</li></ol>$$
f_E^{[1]}(x)=3+4x+5x^2+2x^3 \\
f_O^{[1]}(x)=1+x+9x^2+6x^3
$$<p>where $x\in\{1,148,336,189\}$. Why is $x$ of $f_E^{[1]}$ and $f_O^{[1]}$ on this domain? Note the $x$ of $f_E$ and $f_O$ is $x^2$ on the original domain, which means the new $x$ is $85,85^2,85^4,85^6\mod{337}$. Given the evaluations of $f_E^{[1]},f_O^{[1]}$, we can evaluate $f$ over the domain through the following equations</p>$$
f(1)=f_E^{[1]}(1)+f_O^{[1]}(1),f(-1)=f(336)=f_E^{[1]}(1)-f_O^{[1]}(1) \\
f(85)=f_E^{[1]}(148)+85\cdot{f_O^{[1]}(148)},f(-85)=f(252)=f_E^{[1]}(148)-85\cdot{f_O^{[1]}(148)} \\
f(148)=f_E^{[1]}(336)+148\cdot{f_O^{[1]}(336)},f(-148)=f(189)=f_E^{[1]}(336)-148\cdot{f_O^{[1]}(336)} \\
f(111)=f_E^{[1]}(189)+111\cdot{f_O^{[1]}(189)},f(-111)=f(226)=f_E^{[1]}(189)-111\cdot{f_O^{[1]}(189)}
$$<ol start=2><li>Recursively decompose the polynomials using the same method as the following figure depicts</li></ol><script src=https://cdn.jsdelivr.net/npm/mermaid@10.9.1/dist/mermaid.min.js></script><p class=mermaid>graph TB
A($f$)-->B1("$f_E^{[1]}=3+4x+5x^2+2x^3$")
A-->B2("$f_O^{[1]}=1+x+9x^2+6x^3$")
B1-->C1("$f_E^{[2,1]}=3+5x$")
B1-->C2("$f_O^{[2,2]}=4+2x$")
B2-->C3("$f_E^{[2,3]}=1+9x$")
B2-->C4("$f_O^{[2,4]}=1+6x$")
C1-->D1("$f_E^{[3,1]}=3$")
C1-->D2("$f_O^{[3,2]}=5$")
C2-->D3("$f_E^{[3,3]}=4$")
C2-->D4("$f_O^{[3,4]}=2$")
C3-->D5("$f_E^{[3,5]}=1$")
C3-->D6("$f_O^{[3,6]}=9$")
C4-->D7("$f_E^{[3,7]}=1$")
C4-->D8("$f_O^{[3,8]}=6$")</p><ol start=3><li>Evaluate the polynomials from the bottom to the root</li></ol><p>Finally, we can get the evaluations $[31, 70, 109, 74, 334, 181, 232, 4]$. Before explaining how the IFFT works, I want to introduce another representation of polynomial evaluation, the matrix, to help us understand the IFFT. When evaluating a polynomial with degree $n-1$, we can treat the computation as the mulplication of two matrices as follows:</p>$$
Y_n=\begin{bmatrix}
y_0 \\
y_1 \\
y_2 \\
\vdots \\
y_{n-1}
\end{bmatrix}=
\begin{bmatrix}
1 & 1 & 1 & \cdots & 1\\
1 & x & x^2 & \cdots & x^{n-1} \\
1 & x^2 & x^4 & \cdots & x^{2(n-1)} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x^{n-1} & x^{2(n-1)} & \cdots & x^{(n-1)(n-1)} \\
\end{bmatrix}
\begin{bmatrix}
a_0 \\
a_1 \\
a_2 \\
\vdots \\
a_{n-1}
\end{bmatrix}
$$<p>where $a_i$ is the coefficient and $y_i$ is the evaluation. It is clear that we can use the following equation to compute $\{a_i\}$ from $\{y_i\}$:</p>$$
\begin{bmatrix}
a_0 \\
a_1 \\
a_2 \\
\vdots \\
a_{n-1}
\end{bmatrix}=
\begin{bmatrix}
1 & 1 & 1 & \cdots & 1\\
1 & x & x^2 & \cdots & x^{n-1} \\
1 & x^2 & x^4 & \cdots & x^{2(n-1)} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x^{n-1} & x^{2(n-1)} & \cdots & x^{(n-1)(n-1)} \\
\end{bmatrix}^{-1}
\begin{bmatrix}
y_0 \\
y_1 \\
y_2 \\
\vdots \\
y_{n-1}
\end{bmatrix}
$$<p>Suppose $M_n=
\begin{bmatrix}
1 & 1 & 1 & \cdots & 1\\
1 & x & x^2 & \cdots & x^{n-1} \\
1 & x^2 & x^4 & \cdots & x^{2(n-1)} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x^{n-1} & x^{2(n-1)} & \cdots & x^{(n-1)(n-1)} \\
\end{bmatrix}$. There is a lemma telling us the inverse of $M_n$ is</p>$$
M_n^{-1}=\frac{1}{n}
\begin{bmatrix}
1 & 1 & 1 & \cdots & 1\\
1 & x^{-1} & x^{-2} & \cdots & x^{-(n-1)} \\
1 & x^{-2} & x^{-4} & \cdots & x^{-2(n-1)} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x^{-(n-1)} & x^{-2(n-1)} & \cdots & x^{-(n-1)(n-1)} \\
\end{bmatrix}
$$<p>The correctness of the lemma is natural. We can denote the element of the product of $M_n$ and $M_n^{-1}$ by</p>$$
\sum_{j=0}^{n-1}x^{i\cdot{j}}\frac{x^{-j\cdot{i^\prime}}}{n}=\frac{1}{n}\sum_{j=0}^{n-1}x^{(i-i^\prime)\cdot{j}}
$$<p>where $i,i^\prime\in[0,n)$. When $i=i^\prime$, the result is $1$, which means the elements on the diagonal of the product are $1$; when $i\ne{i^\prime}$, the result is $0$, because $x^n-1=0=(x-1)(1+x+x^2+x^3+\cdots+x^{n-1})\Rightarrow{1+x+x^2+x^3+\cdots+x^{n-1}=0}$ and let $x=x^{i-i^\prime}$.</p><p>Based on the above knowledge, we can compute $\{a_i\}$ from $\{y_i\}$ by multiplying $M_n^{-1}$ and $Y_n$. We have</p>$$
M_n^{-1}
\begin{bmatrix}
y_0 \\
y_1 \\
y_2 \\
\vdots \\
y_{n-1}
\end{bmatrix}=
\frac{1}{n}
\begin{bmatrix}
\sum_{i=0}^{n-1}{y_i} \\
\sum_{i=0}^{n-1}{y_ix^{-i}} \\
\sum_{i=0}^{n-1}{y_ix^{-(2i)}} \\
\vdots \\
\sum_{i=0}^{n-1}{y_ix^{-(n-1)i}} \\
\end{bmatrix}
$$<p>It might not be obivious to see how to relate the FFT with this, as we need to rearrange the equations. Let us start with $\sum_{i=0}^{n-1}{y_ix^{-i}}$. Recall $x$ is an $n$-th root of unity, which means $(x^n)^k=1$, where $k$ is an integer. So we have</p>$$
\begin{align}
\sum_{i=0}^{n-1}{y_ix^{-i}}&=x^n\cdot\sum_{i=0}^{n-1}{y_ix^{-i}}\\
&=x^n(y_0x^0+y_1x^{-1}+y_2x^{-2}+y_3x^{-3}+\cdots+y_{n-1}x^{-(n-1)}) \\
&=y_0x^n+y_1x^{n-1}+y_2x^{n-2}+y_3x^{n-3}+\cdots+y_{n-1}x^{1}
\end{align}
$$
$$
\begin{align}
\sum_{i=0}^{n-1}{y_ix^{-2i}}&=x^{2n}\cdot\sum_{i=0}^{n-1}{y_ix^{-2i}} \\
&=x^{2n}(y_0x^0+y_1x^{-2}+y_2x^{-4}+y_3x^{-6}+\cdots+y_{n-1}x^{-2(n-1)}) \\
&=y_0x^{2n}+y_1x^{2(n-1)}+y_2x^{2(n-2)}+y_3x^{2(n-3)}+\cdots+y_{n-1}x^{2} \\
\end{align}
$$<p>and so on and so forth. Interestingly, the product of $M_n^{-1}Y_n$ is exactly the same as the product of $\frac{1}{n}M_nY_n^\prime$, where</p>$$
Y_n=
\begin{bmatrix}
y_0 \\
y_{n-1} \\
y_{n-2} \\
y_{n-3} \\
\vdots \\
y_1
\end{bmatrix}
$$<p>Therefore, the implementation of the IFFT is quite clear: run the FFT for $\{y_i\}$ first, then let each element of $\{y_i\}$ multiply the multiplicative inverse of $n$ modulo the domain (337 for the above example). (Remember to reorder $\{y_i\}$)</p></section><nav class="mt-24 flex rounded-lg bg-black/[3%] text-lg dark:bg-white/[8%]"><a class="ml-auto flex w-1/2 items-center justify-end rounded-r-md p-6 pl-3 no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]" href=https://shvier.github.io/posts/2024/0813/a-brief-introduction-to-secure-multiparty-computation/><span>A Brief Introduction to Secure Multiparty Computation (MPC)</span><span class=ml-1.5>→</span></a></nav></article></main><footer class="opaco mx-auto flex h-[5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-50"><div class=mr-auto>&copy; 2024
<a class=link href=https://shvier.github.io/>Barry's Site</a></div><a class="link mx-6" href=https://gohugo.io/ rel=noopener target=_blank>Powered by Hugo️️</a>️
<a class=link href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>Theme Paper</a>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/katex.min.css integrity="sha512-mQwom8Ns4op+H29oDkD/LXO/OsXPvCFfkgZkFAVrhhePzRLU8NUI3Nkm43NhWUSmj3p5Cca2HTEkMQmXQRwDQQ==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/katex.min.js integrity="sha512-sHSNLECRJSK+BFs7E8DiFc6pf6n90bLI85Emiw1jhreduZhK3VXgq9l4kAt9eTIHYAcuQBKHL01QKs4/3Xgl8g==" crossorigin=anonymous referrerpolicy=no-referrer></script><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/contrib/auto-render.min.js integrity="sha512-iWiuBS5nt6r60fCz26Nd0Zqe0nbk1ZTIQbl3Kv7kYsX+yKMUFHzjaH2+AnM6vp2Xs+gNmaBAVWJjSmuPw76Efg==" crossorigin=anonymous referrerpolicy=no-referrer onload=renderMathInElement(document.body)></script></footer></body></html>